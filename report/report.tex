\documentclass[a4paper, 11pt]{article}

\usepackage{geometry}
\usepackage{layout}
\geometry{includeheadfoot, margin=3.18cm}
\setlength{\parskip}{0.3cm} \setlength{\parindent}{0cm}

\usepackage{graphicx}
\usepackage{float}
\usepackage{array,booktabs}
\usepackage[style=numeric,sorting=debug,backend=biber]{biblatex}
\usepackage[T1]{fontenc}
\usepackage{todonotes}
\usepackage{paralist}
\addbibresource{report.bib}
\DeclareDatamodelEntrytypes{standard}
\DeclareDatamodelEntryfields[standard]{type,number}
\DeclareBibliographyDriver{standard}{%
  \usebibmacro{bibindex}%
  \usebibmacro{begentry}%
  \usebibmacro{author}%
  \setunit{\labelnamepunct}\newblock
  \usebibmacro{title}%
  \newunit\newblock
  \printfield{number}%
  \setunit{\addspace}\newblock
  \printfield[parens]{type}%
  \newunit\newblock
  \usebibmacro{location+date}%
  \newunit\newblock
  \iftoggle{bbx:url}
    {\usebibmacro{url+urldate}}
    {}%
  \newunit\newblock
  \usebibmacro{addendum+pubstate}%
  \setunit{\bibpagerefpunct}\newblock
  \usebibmacro{pageref}%
  \newunit\newblock
  \usebibmacro{related}%
  \usebibmacro{finentry}}
% Stop Latex from repositioning tables like an idiot
\restylefloat{table}

% Itemised columns
\makeatletter
\newcolumntype{i}[1]{%
    >{\minipage[t]{\linewidth}\let\\\tabularnewline
      \itemize
      \addtolength{\rightskip}{0pt plus 50pt}% for raggedright
      \setlength{\itemsep}{-\parsep}}%
    p{#1}%
    <{\@finalstrut\@arstrutbox\enditemize\endminipage}}
\makeatother


\begin{document}

\begin{center}
  \huge 3rd Year Group Project Final Report \\ [0.4cm]
  \large Sean Allan, Mitchell Allison, Sam Esgate, Tom Harling, Ted Sales,
         Max Tottenham \\ [0.2cm]
  \vspace{0cm}
\end{center}

\section{Executive Summary}
  Our project is, at its heart, a language translator. It translates a
  restricted version of first order predicate logic into the database querying
  language SQL. This allows us to open up new avenues in the realms of
  teaching, database administration, and computer security.

  \subsection*{Security}
  In the world of computer security, access to data is an important topic. One
  which has come to public attention through the recent leaks from NSA
  contracter Edward Snowden. Our product provides the bedrock for an
  information security system. 

  Imagine a scenario where your company needs to work with another large
  organisation, for example a telecommunications company working with the US
  Government. Your company is passionate about your customers privacy rights
  and so you want to give the government as little information as possible
  about your customers, whilst still allowing them to do their job. This could
  be as secretive as not even allowing the governement to know what kinds of
  data you hold. What you would like is a system which would allow the
  goverment to ask you a question, and for you to be able to respond with as
  little information as possible to answer that question without the government
  knowing what information you hold.

  Our product can provide the bedrock for this. Questions can be formed in
  predicate logic about whether a particular entity exists and if certain
  conditions surounding it hold, our project then takes this query and
  translates it into SQL, so that it is ready to be sent to a conventional
  database.

  \subsection*{Teaching}

  A compelling use for our project is for teaching, ideally suited for use 
  by students studying both logic and databases. To reinforce their 
  understanding of logic, queries can be written and tested against a suitably
  populated database of facts. The generated SQL can be used either to 
  highlight issues with the logic or, if correct, to explain the formulation
  of correct SQL.

  It also lends itself well to creating problem sheets for these subjects.
  For example, given a statement in english, like "What are the names of
  dragons that are happy?" what would be the logical expression and equivalent
  SQL query.

  \subsection*{Elevator Pitch (quite a hard sell)}
  \emph{>> What we have...}
  
  We can create SQL queries from logic statements.
  
  \emph{>> Why you want it...}

   It can be used to:
   \begin{itemize}
     \item query a database, without knowledge of SQL
     \item teach the basics of logic and SQL
   \end{itemize}

   \emph{>> Why is it useful...}
   \begin{itemize}
     \item It brings some of the power of logic to regular database queries,
     without the need to migrate to datalog.
    \end{itemize}

  What is your Project? What does it do? Why would I want to buy it? etc.
  No implementation, software engineering details, or project management

\section{Introduction}

  Set the scene ... motivation'
  State the problem you are trying to solve ...objective(s)
  Summarise your main achievements 

When we began this project our goal was simply to allow a database to be 
queried using logic. You shouldn't need to know the syntax of a particular
version of SQL, you shouldn't have to explicitly tell the DBMS how to extract
the data, all you need to do is write a query in logic and we will
get it for you.

We wanted to make it as easy as possible to write queries and view results;
our objective was to make it easy to understand, easy to write and to
provide clear advice when it does go wrong.

At the end of the project we can say that we have achieved most of our initial 
goals. We have created a system that can convert the queries, we have created
a simple way to construct and edit these queries, one that can be changed to 
work on any database and will provide clear error messages.

  -- GOALS - In Chatley coursework 1 --
  TODO: Discuss goals, they're referenced in the Project Management
  section. Revisions should not be talked about here though, just the
  overarching goals of the project.

\section{Theory}

  Structured Query Language (SQL)~\cite{wiki:SQL} is a special-purpose
  programming language designed for managing data held in relational database
  management system. SQL is made up of two different types of language:

  \begin{itemize}
      \item
        Data Definition Language. DDL is used to define the structure of a
        database (also known as its schema.
      \item
        Data Manipulation Language. DML is primarily used to insert, select,
        delete and update data within a database.
  \end{itemize}

  However, as defined by the SQL92 standard\cite{isoSQL}, read-only operations
  such as 'SELECT' (without 'INSERT INTO') should not exist as part of the DML;
  they do not manipulate the data, only query it. However, the distinction
  between read-only and read-write is not enforced. Here we will focus only on
  these operations (so called 'SQL-data' operations), with the aim of purely
  querying the RDBMS without altering it.

  \subsection{Tuple Relational Calculus}
    SQL was originally based on Relational Algebra and Tuple Relational
    Calculus. RA forms the structure and operations that can be performed
    across tuples of data and TRC provides a query language for such a model.

    \subsubsection{Formal Specification of Tuple Relational Calculus\cite{lecRA}}
      A query takes the form: \{T | p(T)\}

      The answer is the set of all tuples T such that p(T) evaluates to true.

      A formula F is recursively defined as:
      \begin{itemize}
        \item $p(t_1, ..., t_n)$ where predicate $p$ is applied to terms $t_1, ..., t_n$ (atomic formula)
        \item $\lnot F$ where $F$ is a formula.
        \item $F' \land F''$ where $F', F''$ are formulae.
        \item $F' \lor F''$ where $F', F''$ are formulae.
        \item $\exists t(F)$ where $F$ is a formula and $t$ is a tuple of terms.
        \item $\forall t(F)$ where $F$ is a formula and $t$ is a tuple of terms.
      \end{itemize}

      $\exists t(F)$ is true if, for some tuple $t$ the formula $F$ is true. \\
      $\forall t(F)$ is true if, for all tuples $t$ the formula $F$ is true.

      A variable $v$ is bound in $F$ if it is of the form:

      $\exists t(F)$ or $\forall t(F)$ and $v \in t$.

      Otherwise $v$ is said to be free.
      
      Note that in query \{T | p(T)\} the variables in T must be the only free variables in p(T).

    \subsubsection{Querying Relational Algebra}
      Using all of this, it is possible to begin formulating some simple
      queries. For example, suppose it was desirable to query all films from a
      particular director in a database. It would be simple to write:

      \{F | F $\in$ Films $\land$ F.director = "Matt Damon"\}

      This would however return all the elements of the tuple. The tuple may
      contain many irrelevant values to the user, and so it would be desirable
      to only return the name of said film. This could be achieved as detailed
      below:

      \{F | $\exists$F1 $\in$ Films(F1.director = "Matt Damon" $\land$ F.name =
      F1.name)\}

      We are now able to represent projection and selection. We can also
      represent joins. Let us suppose that we wish to find all films whose
      director has also directed another film.

      \{F | $\exists$F1 $\in$ Films($\exists$F2 $\in$ Films(Films1.director =
      F2.director $\land$ F1 != F2))\}

  \subsection{Mapping Tuple Relational Calculus to First-order Predicate Logic}
    With the knowledge of TRC, and how it underpins SQL, it is now necessary to
    formulate a mapping between TRC and first order predicate logic.

    \subsubsection{Atoms, Formulae, Predicates}
      Firstly atoms, formulae and predicates remain unchanged. We still wish to
      find a set of tuples that will result in a given formula evaluating to
      true.

    \subsubsection{Set Membership}
      The first difference is set membership. Whereas before we could simply
      test the membership of a tuple $t$ in a relation $R$ with $t \in R$, first order
      predicate logic does not have the notion of set membership. From here
      there are a few different solutions to the problem.

      One solution is with an 'In' predicate, where 'InRelation(t, R)' would
      have the same semantic meaning as the previous set membership test. This
      seems to work, although throughout first order predicate logic, we do not have the
      notion of a tuple. A disadvantage of this would be that accessing members
      of the tuple would require another predicate, for example 'InTuple(a,
      'attrName', t)' which would have the same semantic meaning as 't.a' in
      TRC.

      Another solution, which solves the previous issue, is to generate n-ary
      predicates that represent a tuple. For example, given a relation 'films',
      with columns 'name', 'length' and 'date-released', a predicate
      'films(name, length, date-released)' could be generated, where name,
      length and date-released are all variables. This certainly solves the
      issue the set membership issue, but does add uneccessary bloat to each
      query; relations may have thousands of columns, very few of which are
      likely needed in a given query.

      The solution chosen addresses the issues raised so far.

      For a relation R(k, $a_{1}$, $a_{2}$, ..., $a_{n}$) with primary key k
      and n attributes, n + 1 predicates are generated as follows:
      \begin{enumerate}
        \item R(k)
        \item R\_$a_{1}$(k, a1)
        \item R\_$a_{2}$(k, a2)
        \\ \vdots
        \item[n + 1.] R\_$a_{n}$(k, an)
      \end{enumerate}

      This reduces the number of unncessary attributes in a given query, whilst
      also addressing the representation of a tuple, by relating a tuple to its
      primary key. This does however add the restriction that a primary key
      must exist on a relation in order to be representable in a query.

\section{Design and Implementation}
  Summarise key implementation details (how did you do it? what technology was
  used and why? what other technology was considered, but not used and why?
  Any technical challenges encountered and how addressed?  Any risks
  anticipated, and how mitigated

  Why web interface, why not native?
  Detail the initial design.
    - Focus on components, how they make up the system.
    - How the components are to interact
  Look at interface design.
    - Maybe show mockups
    - Focus on what the user would need rather than what would look
      visually attractive

  \subsection{Front-end site}
    How the site that the user sees works. Talk about javascript, sending data
    to/from server and any plugins we used to make it look nice.

  \subsection{Middle/back end implementation details}
    What server did we use, databases supported (PostgreSQL).

    Maybe talk about continuous integration e.g. TeamCity (although might be
    too much Chatley rubbish)

  \subsection{Lexing and parsing}
    How we defined the language and parsed it. Used python.

  \subsection{Parse tree to SQL}
    How we converted the parse tree to SQL. Lots of scope to talk about each
    different construct (SELECT, SELECT FROM, JOIN, NATURAL JOIN etc.) and
    any optimisations we did.

\section{Evaluation}
  Evaluate your deliverables e.g. performance, usability, etc.
  Summarise testing procedures + relevant testing results

\section{Conclusion and Future Extensions}
  What did you learn? What might you have done differently?
  How would you build on what you have done?

\section{Project Management}
  Planning, group organisation, breakdown + task allocation etc.

  \subsection{Planning}
    \todo[inline]{TODO Should we discuss here how everything went wrong, and
    revisions were missed entirely?}

    As we have learnt from previous projects, inside and outside the
    department, it is critical to thoroughly plan a software engineering
    exercise of this scale before beginning to implement features and write
    code. As discussed in our introduction section, we decomposed our problem
    of translating first order predicate logic to SQL into several key
    subgoals. This enabled us to outline a core feature set which we wished to
    implement and gave us a much clearer idea of how to begin tackling the
    problem.

    Moreover, we initially split the project up in to five major 'revisions'.
    Each revision added a certain amount of functionality to our project, and
    allowed us to continually build upon features already implemented. This
    incremental method of development is one of the key ideas of the Agile
    development methodology to which we adhered to throughout the project.
    \todo[inline]{TODO citation} Additionally, with each revision having a
    deadline, it gave the team a clear plan of what was to be implemented at
    what time.

    \begin{table}[H]
      \centering
      \begin{tabular}{| l | p{0.6\textwidth} | l |}
        \hline
        \textbf{Revision} & \textbf{Necessary Steps for Completion}
          & \textbf{Completion Estimate} \\
        % \multicolumn{1}{p{0.6\textwidth} |}{\textbf{}}
        \hline
        1 &
          \begin{compactitem}
            \item Set up basic web server;
            \item Set up and create a database;
            \item Create simple UI \& communicate with server;
            \item Create 5 sample Logic to SQL translations;
            \item Set up development environment.
          \end{compactitem}
          & 17/10/13 \\
        \hline
        2 &
          \begin{compactitem}
            \item UI sends predicate logic to web server;
            \item Web server parses the logic into an AST;
            \item Backend translates the AST to SQL for basic \texttt{SELECT
              FROM} queries (i.e. projection only);
            \item Create 5 more sample Logic to SQL translations.
          \end{compactitem}
          & 25/10/13 \\
        \hline
        3 &
          \begin{compactitem}
            \item Expand backend parser grammar to include more advanced use of
              SQL queries (selection \& projection);
            \item Dynamic table selection in logic - "smart" logic predicates,
              e.g. \texttt{updated(x)} vs. \texttt{customer\_updated(x)};
            \item Hook into database.
          \end{compactitem}
          & 1/11/13 \\
        \hline
        4 &
          \begin{compactitem}
            \item User-defined functions;
            \item Configurable UI - database settings, and possibly changing the
              UI depending on the user's ability;
            \item Extend backend to use SQL joins.
          \end{compactitem}
          & 8/11/13 \\
        \hline
        5 &
          \begin{compactitem}
            \item Contingency time built in for bug fixes, or additional
              features/extensions depending on the project status (e.g. Semantic
              checks of logical statements before translating to SQL).
          \end{compactitem}
          & 15/11/13 \\
        \hline
      \end{tabular}
      \caption{Feature sets for each revision, as defined at the start of the
        project}
    \end{table}

  \subsection{Group Organisation}
    At the beginning of the project, as discussed previously, we outlined the
    goals and required features of our project, and split them up in to three
    rough areas - front end (handling user interactions),
    middle end (communicating between client and server), and
    then the back end (translation and database access).
    We initially split our group of six in to three teams,
    corresponding to each of the subsections of our project. Members were
    allocated to each team depending on their strengths - initially Ted and Tom
    were to complete front end work, Sam and Mitchell to do middle end, and
    Sean and Max on back end. These were just initial roles, and we found that
    throughout the project, roles could be temporarily switched around to put
    extra work in to tasks that took longer than expected.

    One of the key ways we kept our group organised was through weekly
    meetings.  During each weekly meeting, we discussed what tasks were to be
    completed that week, and spoke in detail about any concerns members had
    about the tasks that had been completed previously. We would also analyse
    the previous weeks performance, and make changes to our plan accordingly.
    This falls in line with a key principle of Agile development, where a team
    must be adapatable to change. An example of such a change is when we
    realised implementing the parser would take significantly longer than
    originally thought. This lead us to modify our feature set, reallocate
    group roles temporarily, and modify deadlines and revision subgoals.

    \missingfigure{Group member Sam questioning the back-end architecture of
      the solution in one of our regular face-to-face meetings. (take pic from
      Chatley cwk 1)}

  \subsection{Tracking}
    Once an overarching plan was agreed on, we split each major goal of each
    revision in to smaller tasks. For each of these tasks, we then allocated a
    numerical estimate of the time it would take to complete, on a scale of 1
    to 5, where 1 signified a short task and 5 signified a very time consuming
    task. The estimate of time a task would take was initially based on
    previous experience on other software engineering projects the group
    participated in, but as the project progressed, we applied knowledge of how
    prior tasks went to more accurately assign estimates.

    A typical practice in Agile development is for developers to write down
    their tasks on cards, and then place them on a physical board (known as an
    "information radiator") located in sight of all developers on the project.
    Upon this board are "swim lanes"; columns which cards belong to, and denote
    their progress (e.g. "to do", "doing" and "done"). Each task has a time
    estimate (as discussed above), and is assigned to one or more people to
    complete.  This allows every developer to know exactly what is happening at
    what time, what has to be done, and what has been completed. For our group,
    working in DoC labs and at home, this would obviously not be practical.
    Therefore, we used web-based project management software called
    Trello. This software behaves in the same way as a physical board, but is
    accessed via a web based interface which can be edited by all members of
    the project.  Additionally, each card has a hashtag which denotes which
    revision a task belongs to, or if a stricter deadline is required, a date
    for completion can be manually added.  Virtual cards are moved between each
    swim lane as the task progresses. The group found this tool indispensible
    for communication and keeping on track with the project.

    \todo[inline]{TODO Citations for the above agile stuff}

    \missingfigure{Picture of our Trello board here. Do we want a screenshot
      from the first week, or towards the end? We have several versions as the
      project progressed in our Chatley reports.}

    -- Trello, Git integration

    -- Burndown chart

    \todo[inline]{TODO Talk about how our project adapated based on user
      feedback, version control (it might seem obvious that Git was used, but
      we should probably mention it along with a brief reason as to why we
      didn't use SVN/Mercurial or whatever). Continuous integration could be
      talked about here, but perhaps that belogs in the software development
      section? I'll see how the other sections are written first, then I'll put
      this stuff in; Anandha places importance on the report flowing, and I
      don't want it to feel disjointed.  Also, there should be a bit more
      discussion about Agile, but I don't know whether it belongs here or not.
      Maybe we should include some brief analysis on how our group found these
      techniques useful?}

\section{Bibliography}
  \printbibliography

  --TODO Agree on referencing practice. The library recommends Harvard. --

  https://workspace.imperial.ac.uk/library/Public/Harvard\_referencing.pdf

\section{Appendix}
  The appendix is optional, and does not count towards the 35 pages. It may
  contain thing like: User guide, installation instructions; more extensive
  design, testing, statistics etc.

\section{Anandha waffle from his site - delete once finished report}
  Final Report ? due: 13th Jan 2014, at 16:00 (both Electronic and Hardcopy)

  Contents for Final Report: The project report should not be longer than 35
  pages (recommended length is around 30 pages), and might be organised
  according to the following structure: see above sections

  Make sure that the final report presents a coherent story. Ask advice from
  your supervisor. You might also draw inspiration from the instructions about
  writing up your individual project.

  Bear in mind, that most of the project assessors will not have followed the
  project throughout and will only have a short time to listen to a
  presentation or see a demonstration. For this reason they will rely heavily
  on the report to judge the project.

  The report should be submitted to SGO in form of a hard copy, as well as
  electronically through CATE. i.e. report.pdf. 

  ------------------------

  Assessment
  Will be updated soon.

  Group project
  The group project assessment is undertaken by each group's supervisor, and
  moderated by a larger group of assessors, who will attend your presentation,
  and/or read your final report. The assessment is based on:

      Executive Summary, 5
      Presentation, 10
      Group Collaboration and Management, 20
      Report, 30
      Technical Achievement, 35

  The group project (along with the Software Engineering course) is worth 440
  Marks for both the MEng and BEng students.
  Overall assessment
  The overall assessment is the sum of the group project component and the
  Software Engineering Course in an 80:20 split.

\end{document}
